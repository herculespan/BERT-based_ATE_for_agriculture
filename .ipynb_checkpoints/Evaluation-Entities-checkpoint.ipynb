{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a792cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from architectures import BertModel, RobertaModel\n",
    "from transformers import BertTokenizerFast, RobertaTokenizerFast\n",
    "from evaluation_utils import get_sentence_predicted_annotation, evaluate, get_annotated_entities\n",
    "from evaluation_utils import get_entities_positions, get_entity_annotation_metrics\n",
    "from utils import align_word_ids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_structures import DataSequence\n",
    "from config import MAX_LENGTH, LABEL_ALL_TOKENS, BATCH_SIZE\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afda91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_lemma(token: str) -> str:\n",
    "    if len(token) > 1:\n",
    "        doc = nlp(token)\n",
    "        return doc[0].lemma_\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18e2ae",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464c886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'./best_models/0*allenai-scibert_scivocab_cased_sgd_0.001_0.35_0_True.pt'\n",
    "#'./best_models/0*recobo-agriculture-bert-uncased_sgd_0.001_0.35_0_True.pt'\n",
    "BEST_MODELS_PATH = './best_models/0*allenai-scibert_scivocab_cased_sgd_0.001_0.35_0_True.pt'\n",
    "# 'recobo/agriculture-bert-uncased'\n",
    "# 'allenai/scibert_scivocab_cased'\n",
    "PRETRAINED_MODEL = 'allenai/scibert_scivocab_cased'\n",
    "IDS_TO_LABELS = {0: 'B-Agr', 1: 'I-Agr', 2: 'O'}\n",
    "UNIQUE_LABELS = {'I-Agr', 'O', 'B-Agr'}\n",
    "SENTENCE_TO_ANNOTATE = 'In addition, it also does not seem to be justifiable to assume that the breed fights against fitness'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549e85c",
   "metadata": {},
   "source": [
    "#### Loading Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6402dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(BEST_MODELS_PATH)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a21792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "syns_labels = []\n",
    "with open(\"labels/synonym-labels-used.txt\", \"r\") as concepts_file:\n",
    "    lines = concepts_file.readlines()\n",
    "    syns_labels = [concept.strip() for concept in lines]\n",
    "    \n",
    "novel_labels = []\n",
    "with open(\"labels/novel-labels-used.txt\", \"r\") as concepts_file:\n",
    "    lines = concepts_file.readlines()\n",
    "    novel_labels = [concept.strip() for concept in lines]\n",
    "\n",
    "pref_labels = []\n",
    "with open(\"labels/pref-labels-used.txt\", \"r\") as concepts_file:\n",
    "    lines = concepts_file.readlines()\n",
    "    pref_labels = [concept.strip() for concept in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d1de1",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_novel_label(annotation):\n",
    "    for novel_label in novel_labels:\n",
    "        if annotation.strip().casefold() == novel_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == novel_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == get_lemma(novel_label.casefold()):\n",
    "            return True  \n",
    "    return False\n",
    "\n",
    "def is_syns_label(annotation):\n",
    "    for syn_label in syns_labels:\n",
    "        if annotation.strip().casefold() == syn_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == syn_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == get_lemma(syn_label.casefold()):\n",
    "            return True  \n",
    "    return False\n",
    "\n",
    "def is_pref_label(annotation):\n",
    "    for pref_label in pref_labels:\n",
    "        if annotation.strip().casefold() == pref_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == pref_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) == get_lemma(pref_label.casefold()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_partial_pref_label(annotation):\n",
    "    for pref_label in pref_labels:\n",
    "        if annotation.strip().casefold() in pref_label.casefold():\n",
    "            return True\n",
    "        elif get_lemma(annotation.strip()) in pref_label.casefold():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249846ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_annotated_entities(annotations_path: str):\n",
    "    df_test = pd.read_csv(annotations_path)\n",
    "    total_real_entities = 0\n",
    "    total_complete_entities_annotated = 0\n",
    "    total_partial_entities_annotated = 0\n",
    "    total_false_positives = 0\n",
    "    all_annotated_entities = []\n",
    "    clean_annotated_entities = []\n",
    "\n",
    "    for sentence, annotation in zip(df_test['text'], df_test['labels']):\n",
    "        predicted_annotations = get_sentence_predicted_annotation(model, tokenizer, sentence, IDS_TO_LABELS)\n",
    "        real_annotations = annotation.split(\" \")\n",
    "        if len(predicted_annotations) == len(real_annotations):\n",
    "            #print(sentence)\n",
    "            #print(predicted_annotations)\n",
    "            #print(real_annotations)\n",
    "            annotated_entities = get_annotated_entities(sentence, predicted_annotations)\n",
    "            if len(annotated_entities) > 0:\n",
    "                all_annotated_entities+=annotated_entities\n",
    "            real_entities = get_entities_positions(real_annotations)\n",
    "            predicted_entities = get_entities_positions(predicted_annotations)\n",
    "            num_complete_entities_annotated, num_partial_entities_annotated, num_false_positive_annotations = get_entity_annotation_metrics(real_entities, predicted_entities)\n",
    "            #print(num_complete_entities_annotated, num_partial_entities_annotated)\n",
    "            total_real_entities+=len(real_entities)\n",
    "            total_complete_entities_annotated+=num_complete_entities_annotated\n",
    "            total_partial_entities_annotated+=num_partial_entities_annotated\n",
    "            total_false_positives+=num_false_positive_annotations\n",
    "            #print()\n",
    "    print(round(np.mean(total_complete_entities_annotated/total_real_entities), 4))\n",
    "    print(round(np.mean(total_partial_entities_annotated/total_real_entities), 4))\n",
    "    print(round(np.mean(total_false_positives/total_real_entities), 4))\n",
    "\n",
    "    #print(all_annotated_entities)\n",
    "\n",
    "    for annotated_entity in all_annotated_entities:\n",
    "        if type(annotated_entity) != str:\n",
    "            clean_annotated_entities.append(\" \".join(annotated_entity))\n",
    "        else:\n",
    "            clean_annotated_entities.append(annotated_entity)\n",
    "            \n",
    "    clean_annotated_entities = list(set(clean_annotated_entities))\n",
    "    return clean_annotated_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27dd072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5746\n",
      "0.0\n",
      "0.2514\n"
     ]
    }
   ],
   "source": [
    "novel_annotated_entities = get_all_annotated_entities('datasets/novel-agri-ner-input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129509c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319\n",
      "0.0\n",
      "0.2029\n"
     ]
    }
   ],
   "source": [
    "syns_annotated_entities = get_all_annotated_entities('datasets/synonym-agri-ner-input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80da527e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13245ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for annotation in novel_annotated_entities:\n",
    "    if not is_novel_label(annotation)\\\n",
    "    and not is_pref_label(annotation)\\\n",
    "    and not is_syns_label(annotation):\n",
    "        print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14f9f246",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m annotation \u001b[38;5;129;01min\u001b[39;00m novel_annotated_entities:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_syns_label(annotation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_pref_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(annotation)\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mis_pref_label\u001b[0;34m(annotation)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m get_lemma(annotation\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;241m==\u001b[39m pref_label\u001b[38;5;241m.\u001b[39mcasefold():\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mget_lemma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m get_lemma(pref_label\u001b[38;5;241m.\u001b[39mcasefold()):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_lemma\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lemma\u001b[39m(token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m doc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlemma_\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/spacy/language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1020\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/spacy/pipeline/tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 125\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m batch_id \u001b[38;5;241m=\u001b[39m Tok2VecListener\u001b[38;5;241m.\u001b[39mget_batch_id(docs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m listener \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlisteners:\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/with_array.py:73\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     71\u001b[0m lengths \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     72\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m---> 73\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[1;32m     76\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/layernorm.py:25\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[InT, Callable]:\n\u001b[0;32m---> 25\u001b[0m     N, mu, var \u001b[38;5;241m=\u001b[39m \u001b[43m_get_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     Xhat \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m mu) \u001b[38;5;241m*\u001b[39m var \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     27\u001b[0m     Y, backprop_rescale \u001b[38;5;241m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/layers/layernorm.py:77\u001b[0m, in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     75\u001b[0m mu: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m var: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvar(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-08\u001b[39m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Floats2d, \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), mu, var\n",
      "File \u001b[0;32m~/anaconda3/envs/agri-ner/lib/python3.9/site-packages/thinc/backends/ops.py:665\u001b[0m, in \u001b[0;36mOps.asarray_f\u001b[0;34m(self, data, dtype)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray_f\u001b[39m(\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    661\u001b[0m     data: Union[FloatsXd, Sequence[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    663\u001b[0m     dtype: Optional[DTypes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    664\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FloatsXd:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(FloatsXd, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for annotation in novel_annotated_entities:\n",
    "    if is_novel_label(annotation) and not is_pref_label(annotation):\n",
    "        print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation in syns_annotated_entities:\n",
    "    if is_syns_label(annotation) and not is_pref_label(annotation):\n",
    "        print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefd4bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conservation\n",
      "contaminants\n",
      "waves\n",
      "distribution\n",
      "transmission\n",
      "BMI\n",
      "economy\n",
      "substrates\n",
      "Turkey\n",
      "economies\n",
      "cortisol\n",
      "QTL\n",
      "Drawings\n",
      "exploitation\n",
      "generations\n",
      "emergence\n",
      "leisure\n",
      "mapping\n",
      "work organisation\n",
      "ACTH\n",
      "Impacts\n",
      "decay\n",
      "dispersion\n",
      "work\n",
      "Britain\n",
      "Compression\n",
      "Distribution\n",
      "permits\n",
      "antagonists\n",
      "stations\n",
      "biofilms\n",
      "distributions\n",
      "insects\n",
      "ticks\n",
      "impacts\n",
      "compression\n",
      "SNPs\n",
      "repair\n",
      "chemotherapy\n",
      "GIS\n",
      "Corticosteroids\n",
      "pathophysiology\n",
      "people\n",
      "embryos\n",
      "Insects\n",
      "boxes\n",
      "propagation\n",
      "architecture\n",
      "Cortisol\n",
      "eukaryotes\n",
      "GPS\n",
      "sonication\n",
      "photoperiod\n",
      "perception\n",
      "works\n",
      "cities\n"
     ]
    }
   ],
   "source": [
    "for clean_annotation in novel_annotated_entities:\n",
    "    if is_novel_label(clean_annotation) and not is_pref_label(clean_annotation):\n",
    "        print(clean_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0a736e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body fat\n",
      "SNP\n",
      "fat content\n",
      "ACTH\n",
      "Oil content\n",
      "hemoglobin\n",
      "endocrine control\n",
      "Fat content\n",
      "speech\n",
      "Plots\n",
      "dissolution\n",
      "sonication\n",
      "Thermal treatment\n",
      "hyperglycemia\n",
      "substrates\n",
      "eukaryotes\n",
      "rDNA\n",
      "Exercise\n",
      "allergy\n",
      "CNS\n",
      "organisation\n",
      "filtering\n",
      "Puberty\n",
      "Estimation\n",
      "molecular markers\n",
      "organic farming\n",
      "Anesthesia\n",
      "infectivity\n",
      "nephropathy\n",
      "estimation\n",
      "exercises\n",
      "antibiotic resistance\n",
      "puberty\n",
      "Renal function\n",
      "Molecular markers\n",
      "Organic farming\n",
      "genetic manipulation\n",
      "food webs\n",
      "food preferences\n",
      "stirring\n",
      "cortisol\n",
      "Cortisol\n",
      "precision farming\n",
      "flavor\n",
      "feces\n",
      "contaminants\n",
      "fibers\n",
      "Aluminum\n",
      "BMI\n",
      "Filtering\n",
      "hemorrhage\n",
      "GPS\n",
      "oil content\n",
      "lifespan\n",
      "ischemia\n",
      "QTL\n"
     ]
    }
   ],
   "source": [
    "for clean_annotation in clean_annotated_entities:\n",
    "    if is_alt_label(clean_annotation)\\\n",
    "     and not is_pref_label(clean_annotation)\\\n",
    "     and not is_partial_pref_label(clean_annotation):\n",
    "        print(clean_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3dd6a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA\n",
      "FSH\n",
      "questionnaire\n",
      "ages\n",
      "men\n",
      "AGE\n",
      "densities\n",
      "sex\n",
      "methodologies\n",
      "language\n",
      "sap\n",
      "air\n",
      "societies\n",
      "age\n",
      "chromosome\n",
      "DNA\n",
      "wind\n",
      "gene\n",
      "accuracies\n",
      "ICE\n",
      "structure\n",
      "ABA\n",
      "laboratory\n",
      "technologies\n",
      "abilities\n",
      "virus\n",
      "equilibria\n",
      "attitude\n",
      "sexes\n",
      "dairy\n",
      "limb\n",
      "ATP\n",
      "efficiencies\n",
      "genome\n",
      "Sun\n",
      "additive\n",
      "lipid\n"
     ]
    }
   ],
   "source": [
    "for clean_annotation in clean_annotated_entities:\n",
    "    if not is_alt_label(clean_annotation) and is_pref_label(clean_annotation):\n",
    "        print(clean_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c352653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "food web\n",
      "inference\n",
      "personality\n",
      "meals\n",
      "develop\n",
      "understanding\n",
      "eps\n",
      "biomarkers\n",
      "University\n",
      "exclusion\n",
      "mating behavior\n",
      "punishment\n",
      "surgery\n",
      "MRI\n",
      "endometriosis\n",
      "Optics\n",
      "recording\n",
      "categories\n",
      "schema\n",
      "dissemination\n",
      "sequencing\n",
      "analgesia\n",
      "Sequencing\n",
      "choice\n",
      "behavioral control\n",
      "alignment\n",
      "economic\n",
      "transposition\n",
      "optimization\n",
      "mating types\n",
      "genetic architecture\n",
      "autism\n",
      "reasoning\n",
      "glycosylation\n",
      "transcripts\n",
      "SA perception\n",
      "Transposition\n",
      "places\n",
      "Oil\n",
      "genetic origin\n",
      "SNPs\n",
      "QTL mapping\n",
      "sequence\n",
      "matching\n",
      "dissipation\n",
      "luciferase\n",
      "intraocular\n",
      "genetic values\n",
      "eating behavior\n",
      "Slow\n",
      "conservation practices\n",
      "resistivity\n",
      "flows\n",
      "integrity\n",
      "Reducing power\n",
      "striatum\n",
      "In vivo\n",
      "schemes\n",
      "Validation\n",
      "tumors\n",
      "discharges\n",
      "nursing\n",
      "cervix\n",
      "SSR markers\n",
      "fertilizer treatments\n",
      "donors\n",
      "cognition\n",
      "registers\n",
      "birth cohort\n",
      "neurons\n",
      "mobility\n",
      "insight\n",
      "articles\n",
      "metformin\n",
      "satisfaction\n",
      "reperfusion\n",
      "sensing\n",
      "surveillance\n",
      "conjugation\n",
      "mechanisms\n",
      "thermal\n",
      "Community structure\n",
      "pathways\n",
      "sexual behavior\n",
      "sepsis\n",
      "Efficiencies\n",
      "dilation\n",
      "images\n",
      "food system\n",
      "flexibility\n",
      "scoring\n",
      "waist circumference\n",
      "ink\n",
      "ligation\n",
      "formats\n",
      "statistical power\n",
      "editing\n",
      "Xenopus\n",
      "GRASS\n",
      "social behavior\n",
      "Residuals\n",
      "serotype\n",
      "Software\n",
      "participants\n",
      "RNAi\n",
      "miRNAs\n",
      "redistribution\n",
      "stroma\n",
      "validation\n",
      "plant architecture\n",
      "practices\n",
      "Oxford\n",
      "pups\n",
      "grammar\n",
      "warming\n",
      "outcomes\n",
      ":\n",
      "packages\n",
      "genetic\n",
      "Participants\n",
      "modules\n",
      "adoption\n",
      "astrocytes\n",
      "stiffness\n",
      "farming practices\n",
      "sequences\n",
      "gene discovery\n",
      "hepatocytes\n",
      "prognosis\n",
      "genetic mapping\n",
      "ethidium bromide\n",
      "tumours\n",
      "markers\n",
      "imaging\n",
      "robustness\n",
      "in situ\n",
      "Linux\n",
      "happiness\n",
      "prototyping\n",
      "routing\n",
      "cell lines\n",
      "monetary policy\n",
      "vesicles\n",
      "amplification\n",
      "Infancy\n",
      "secondary structure\n",
      "BAC\n",
      "autophagy\n",
      "soft\n",
      "proteome\n",
      "standardization\n",
      "RFID\n",
      "telomerase\n",
      "ends\n",
      "added value\n",
      "rotation\n",
      "covers\n",
      "treatments\n",
      "cell types\n",
      "writing\n",
      "power law\n",
      "decision makers\n",
      "etching\n",
      "attenuation\n",
      "software\n",
      "DNA sequencing\n",
      "flavor perception\n",
      "columns\n",
      "Association\n",
      "motion\n",
      "GWAS\n",
      "graphs\n",
      "genetic structure\n",
      "creep\n",
      "rigidity\n",
      "molecular\n",
      "Plant cultivars\n",
      "expression\n",
      "childhood\n",
      "Blast\n",
      "intracranial\n",
      "DNase I\n",
      "chaos\n"
     ]
    }
   ],
   "source": [
    "for clean_annotation in clean_annotated_entities:\n",
    "    if not is_alt_label(clean_annotation) and not is_pref_label(clean_annotation):\n",
    "        print(clean_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aeb0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2a1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
